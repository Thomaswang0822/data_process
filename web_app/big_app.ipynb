{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f3e51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application Starting\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FIlE NAME: big_app.ipynb\n",
    "\n",
    "This is the integreated, web-based app designed to process the raw data (in csv format)\n",
    "generated by Virtual Test Drive (by VIRES company) RDB Sniffer runtime tool.\n",
    "\n",
    "Structure:\n",
    "1. Setup, get working dir by interacting with the user\n",
    "2. do data process for each raw csv (representing data from one package)\n",
    "3. ask for an output dir and join those csv (currently 5) to a big csv\n",
    "4. setup socket config and send the big csv to a remote server (another computer)\n",
    "\"\"\"\n",
    "print(\"Application Starting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55418549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ignore following lines, from here...\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "Enabling: voila\n",
      "- Writing config: /Users/thomas/opt/anaconda3/etc/jupyter\n",
      "    - Validating...\n",
      "      voila 0.2.10 \u001b[32mOK\u001b[0m\n",
      "to here. The app is setting up its configuration\n"
     ]
    }
   ],
   "source": [
    "# Setup voila, which turns code into app\n",
    "print(\"Please ignore following lines, from here...\")\n",
    "\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!jupyter serverextension enable voila --sys-prefix\n",
    "\n",
    "print(\"to here. The app is setting up its configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb2639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing necessary python packages.\n",
      "sucessfully importing packages\n"
     ]
    }
   ],
   "source": [
    "# import necessary modules\n",
    "print(\"importing necessary python packages.\")\n",
    "# These are built-in packages in std lib\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import socket\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import easygui as eg   \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"At least one of the python packages of [pandas, numpy, easygui] is not installed.\")\n",
    "    print(\"Please use command 'pip install <package-name>' to install your missing package.\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"sucessfully importing packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1eff0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure that the following files have 5 .csv files ending in pkg_5, pkg_7, pkg_9, pkg_10, pkg_20 accordingly.\n",
      "['2_18pkg5.csv', '2_18pkg7.csv', '2_18pkg10.csv', 'video_1.avi', '2_18pkg20.csv', '2_18pkg9.csv']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set up source dir (storing raw csv) on user's choice\n",
    "\"\"\"\n",
    "\n",
    "DATA_DIR = eg.diropenbox(title=\"Choose the folder with the 5 raw csv.\", default=\"../\")\n",
    "print(\"Make sure that the following files have 5 .csv files ending in pkg_5, pkg_7, pkg_9, pkg_10, pkg_20 accordingly.\")\n",
    "print(os.listdir(DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d3f76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the csv file 2_18pkg5.csv in your folder. The process will start now.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following chunks of code process pkg5 data\n",
    "\"\"\"\n",
    "# Define constants\n",
    "\n",
    "# Get ___pkg5.csv full path\n",
    "file_found = False\n",
    "for f in os.listdir(DATA_DIR):\n",
    "    if len(f) >= 8 and f[-8:]==\"pkg5.csv\":\n",
    "        FILE_PATH = os.path.join(DATA_DIR, f)\n",
    "        file_found = True\n",
    "        break\n",
    "try:\n",
    "    assert file_found==True, \"There is no file ending with pkg5.csv in the folder you choose\"\n",
    "except AssertionError as e:\n",
    "    print(\"The app will exit. Please reopen the app and choose the correct folder.\")\n",
    "    time.sleep(3)\n",
    "    sys.exit()\n",
    "\n",
    "# We want id, type, color, and lateralDist\n",
    "# which are in col index 3, 16, 17, 6\n",
    "index_to_keep = [0,1,3,6]\n",
    "PATTERN = 16  # number of entries of one road line, which form a pattern\n",
    "col_of_one = [\"id\", \"lateralDist\", \"type\", \"color\"]\n",
    "\n",
    "print(f\"Found the csv file {f} in your folder. The process will start now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb2f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview the raw csv. The correct column names are not read in because they may not be complete (long enough). Will be fixed later\n",
      "                    temp.0                   temp.1                   temp.2  \\\n",
      "0  +9.9999997764825821e-03                        2                        2   \n",
      "1  +1.9999999552965164e-02                        3                        2   \n",
      "2  +2.9999999329447746e-02                        4                        2   \n",
      "3  +3.9999999105930328e-02                        5                        2   \n",
      "4  +4.9999998882412910e-02                        6                        2   \n",
      "\n",
      "                    temp.3                   temp.4                   temp.5  \\\n",
      "0                        1                       -1                      0x1   \n",
      "1                        1                       -1                      0x1   \n",
      "2                        1                       -1                      0x1   \n",
      "3                        1                       -1                      0x1   \n",
      "4                        1                       -1                      0x1   \n",
      "\n",
      "                    temp.6                   temp.7                   temp.8  \\\n",
      "0  +5.0000000000000000e+01  -1.8750000000000000e+00  -7.3718808835110394e-14   \n",
      "1  +5.0000148773193359e+01  -1.8750000000000000e+00  -7.8603790143461083e-14   \n",
      "2  +5.0000400543212891e+01  -1.8750000000000000e+00  +7.9936057773011271e-15   \n",
      "3  +5.0000751495361328e+01  -1.8750000000000000e+00  -1.2123635428906709e-13   \n",
      "4  +5.0001201629638672e+01  -1.8750000000000000e+00  -1.3455903058456897e-13   \n",
      "\n",
      "                    temp.9  ...                  temp.17  \\\n",
      "0  +3.9719338928989600e-11  ...                      0x1   \n",
      "1  +3.9719338928989600e-11  ...                      0x1   \n",
      "2  +3.9719338928989600e-11  ...                      0x1   \n",
      "3  +3.9719338928989600e-11  ...                      0x1   \n",
      "4  +3.9719338928989600e-11  ...                      0x1   \n",
      "\n",
      "                   temp.18                  temp.19                  temp.20  \\\n",
      "0  +2.6191341876983643e+00  -2.0055880546569824e+00  -1.3058812916278839e-01   \n",
      "1  +2.6191337108612061e+00  -2.0055880546569824e+00  -1.3058812916278839e-01   \n",
      "2  +2.6191329956054688e+00  -2.0055880546569824e+00  -1.3058812916278839e-01   \n",
      "3  +2.6191325187683105e+00  -2.0055880546569824e+00  -1.3058812916278839e-01   \n",
      "4  +2.6191318035125732e+00  -2.0055880546569824e+00  -1.3058812916278839e-01   \n",
      "\n",
      "                   temp.21                  temp.22                  temp.23  \\\n",
      "0  -2.8035880532115698e-03  -1.9817599095404148e-03  +1.9151747619122342e-19   \n",
      "1  -2.8035880532115698e-03  -1.9826483912765980e-03  +2.5633396604829205e-19   \n",
      "2  -2.8035880532115698e-03  -1.9838376902043819e-03  +3.7905233622694543e-19   \n",
      "3  -2.8035880532115698e-03  -1.9852824043482542e-03  +4.1625266462619818e-19   \n",
      "4  -2.8035880532115698e-03  -1.9869192037731409e-03  +4.3106173083152332e-19   \n",
      "\n",
      "                   temp.24                  temp.25 temp.26  \n",
      "0                        0  +2.6191341876983643e+00     NaN  \n",
      "1                        0  +2.6191337108612061e+00     NaN  \n",
      "2                        0  +2.6191329956054688e+00     NaN  \n",
      "3                        0  +2.6191325187683105e+00     NaN  \n",
      "4                        0  +2.6191318035125732e+00     NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" read in the csv and preview.\"\"\"\n",
    "with open(FILE_PATH, 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    MAX_LEN = max(len(_) for _ in reader)\n",
    "\n",
    "    \n",
    "original_col_names = [\"temp.{}\".format(i) for i in range(MAX_LEN)]\n",
    "df5 = pd.read_csv(FILE_PATH, names=original_col_names, low_memory=False)        \n",
    "\n",
    "df5.drop(index=0, axis=0, inplace=True)\n",
    "df5.index -= 1\n",
    "df5.columns = [name.strip() for name in df5.columns]\n",
    "      \n",
    "print(\"Preview the raw csv. The correct column names are not read in because they may not be complete (long enough). Will be fixed later\")\n",
    "print(df5.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4983366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an empty col at the end\n",
      "Please check the following value count of id in each playerId column\n",
      "All id values should either be a non-negative whole number (in int or float) or a place holder -99.99\n",
      "2    3800\n",
      "Name: playerId_0, dtype: int64\n",
      "1    3800\n",
      "Name: playerId_1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Start pre-processing \"\"\"\n",
    "# only keep till the last hundreds of rows\n",
    "# They are safe to and should be deleted because 100 rows <=> 1s in the simulation, and ending row is often incomplete\n",
    "rows = df5.shape[0]\n",
    "num_del = rows%100\n",
    "df5.drop(labels=range(rows-num_del, rows), axis=0, inplace=True)\n",
    "\n",
    "# Automatically define other const dependent on the dataframe\n",
    "while (len(df5.columns)-2)%PATTERN != 0:\n",
    "    # del that col\n",
    "    print(\"Found an empty col at the end\")\n",
    "    df5.drop(df5.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "NUM_OBJS = (len(df5.columns)-2)//PATTERN\n",
    "BEGIN_IDX = NUM_OBJS \n",
    "TARGET = 10 # we want 14\n",
    "END_IDX = 10\n",
    "\n",
    "# delete unused columns\n",
    "cols_to_del = [name for i, name in enumerate(df5.columns) if (i%PATTERN not in index_to_keep and i!=1)]\n",
    "df5 = df5.drop(columns=cols_to_del)\n",
    "\n",
    "\n",
    "# Some other process\n",
    "df5.fillna(PLACE_HOLDER, inplace=True)\n",
    "df5.rename(columns={\"temp.1\":\"simFrame\"}, inplace=True)\n",
    "df5[\"simFrame\"] = df5[\"simFrame\"].astype(np.int64)\n",
    "df5.set_index(\"simFrame\", inplace=True)\n",
    "df5 = df5[~df5.index.duplicated(keep='first')]\n",
    "\n",
    "# replace temp column names with column names we want\n",
    "new_names = [\"{}_{}\".format(name,i) for i in range(NUM_OBJS) for name in col_of_one]\n",
    "df5.columns = new_names\n",
    "\n",
    "# format all id entries because they server important use later\n",
    "print(f\"Please check the following value count of id in each {col_of_one[0]} column\")\n",
    "print(f\"All id values should either be a non-negative whole number (in int or float) or a place holder {PLACE_HOLDER}\")\n",
    "for i in range(NUM_OBJS):\n",
    "    df5[\"{}_{}\".format(col_of_one[0], i)] = df5[\"{}_{}\".format(col_of_one[0], i)].apply(lambda x: int(x.strip()) if type(x)==str else x)\n",
    "    print( df5[\"{}_{}\".format(col_of_one[0], i)].value_counts())\n",
    "    \n",
    "# append empty colunms to match designated number of lines reserved: 14\n",
    "for i in range(BEGIN_IDX, END_IDX):\n",
    "    for name in col_of_one:\n",
    "        df5[name+'_'+str(i)] = PLACE_HOLDER\n",
    "               \n",
    "NUM_OBJS = END_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3763da86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting started. This may take several seconds up to several minutes, please be patient.\n",
      "Sorting complete. Proceed to next step.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MOST important task: Standardization.\n",
    "\n",
    "Details explained in the file doc\n",
    "  \n",
    "!!! May take quite a long time\n",
    "\"\"\"\n",
    "print(\"Sorting started. This may take several seconds up to several minutes, please be patient.\")\n",
    "\n",
    "row_nums = df5.shape[0]    # 4760 this time\n",
    "jump = len(col_of_one)   # 2\n",
    "\n",
    "for row in range(row_nums):\n",
    "    old_row = df5.iloc[row]\n",
    "    new_row = [ [PLACE_HOLDER]*jump ]*NUM_OBJS\n",
    "\n",
    "    \n",
    "    # NOTICE: We only have 4 distinct playerId 1-4, but the raw data have 5 chunks\n",
    "    # Checking raw data, we find there are duplicate chunks\n",
    "    for idx in range(0, 0 + NUM_OBJS*jump, jump):   # 0, 14, 28, ...\n",
    "        objId = old_row[idx]\n",
    "        if objId == PLACE_HOLDER:\n",
    "            # Special case where id is placeholder -99.99 (also those trailing data)\n",
    "            continue\n",
    "        else:\n",
    "            objId = int(objId)\n",
    "            # ego car id=1 should go to objectId_0, id=5 should go to objectId=4 likewise.\n",
    "            new_row[objId] = old_row[idx:idx+jump]\n",
    "            \n",
    "    # flat the list\n",
    "    new_row = [item for sublist in new_row for item in sublist]\n",
    "    df5.iloc[row] = new_row\n",
    "\n",
    "# do the check after the sort, there should be no output if it's correct\n",
    "for i in range(END_IDX):\n",
    "    row_count = dict(df5[\"{}_{}\".format(col_of_one[0], i)].value_counts())\n",
    "    for key in row_count:\n",
    "        assert key==PLACE_HOLDER or key==i, f\"column {col_of_one[0]}.{i} \\\n",
    "                has wrong id value other than {PLACE_HOLDER} and {i}\"\n",
    "    assert len(row_count) <= 2\n",
    "    \n",
    "    \n",
    "print(\"Work complete. Proceed to csv of pkg7.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba498ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d4080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d3e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b2e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following chunks of code process pkg7 data\n",
    "\"\"\"\n",
    "\n",
    "# Define constants\n",
    "\n",
    "# Get ___pkg7.csv full path\n",
    "file_found = False\n",
    "for f in os.listdir(DATA_DIR):\n",
    "    if len(f) >= 8 and f[-8:]==\"pkg7.csv\":\n",
    "        FILE_PATH = os.path.join(DATA_DIR, f)\n",
    "        file_found = True\n",
    "        break\n",
    "try:\n",
    "    assert file_found==True, \"There is no file ending with pkg7.csv in the folder you choose\"\n",
    "except AssertionError as e:\n",
    "    print(\"The app will exit. Please reopen the app and choose the correct folder.\")\n",
    "    time.sleep(3)\n",
    "    sys.exit()\n",
    "\n",
    "# We want playerId and laneId\n",
    "# which are in col index 2,4\n",
    "index_to_keep = [2,4,6,7,9]\n",
    "PATTERN = 12  # number of entries of one road line, which form a pattern\n",
    "col_of_one = [\"playerId\", \"laneId\",\"roadS\", \"roadT\", \"hdgRel\"]\n",
    "\n",
    "PLACE_HOLDER = -99.99\n",
    "\n",
    "print(f\"Found the csv file {f} in your folder. The process will start now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ad5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" read in the csv and preview.\"\"\"\n",
    "with open(FILE_PATH, 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    MAX_LEN = max(len(_) for _ in reader)\n",
    "\n",
    "    \n",
    "original_col_names = [\"temp.{}\".format(i) for i in range(MAX_LEN)]\n",
    "df7 = pd.read_csv(FILE_PATH, names=original_col_names, low_memory=False)        \n",
    "\n",
    "df7.drop(index=0, axis=0, inplace=True)\n",
    "df7.index -= 1\n",
    "df7.columns = [name.strip() for name in df7.columns]\n",
    "      \n",
    "print(\"Preview the raw csv. The correct column names are not read in because they may not be complete (long enough). Will be fixed later\")\n",
    "print(df7.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Start pre-processing \"\"\"\n",
    "# only keep till the last hundreds of rows\n",
    "# They are safe to and should be deleted because 100 rows <=> 1s in the simulation, and ending row is often incomplete\n",
    "rows = df7.shape[0]\n",
    "num_del = rows%100\n",
    "df7.drop(labels=range(rows-num_del, rows), axis=0, inplace=True)\n",
    "\n",
    "# Automatically define other const dependent on the dataframe\n",
    "while (len(df7.columns)-2)%PATTERN != 0:\n",
    "    # del that col\n",
    "    print(\"Found an empty col at the end\")\n",
    "    df7.drop(df7.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "NUM_OBJS = (len(df7.columns)-2)//PATTERN\n",
    "BEGIN_IDX = NUM_OBJS \n",
    "TARGET = 10 # we want 14\n",
    "END_IDX = 10\n",
    "\n",
    "# delete unused columns\n",
    "cols_to_del = [name for i, name in enumerate(df7.columns) if (i%PATTERN not in index_to_keep and i!=1)]\n",
    "df7 = df7.drop(columns=cols_to_del)\n",
    "\n",
    "\n",
    "# Some other process\n",
    "df7.fillna(PLACE_HOLDER, inplace=True)\n",
    "df7.rename(columns={\"temp.1\":\"simFrame\"}, inplace=True)\n",
    "df7[\"simFrame\"] = df7[\"simFrame\"].astype(np.int64)\n",
    "df7.set_index(\"simFrame\", inplace=True)\n",
    "df7 = df7[~df7.index.duplicated(keep='first')]\n",
    "\n",
    "# replace temp column names with column names we want\n",
    "new_names = ['simTime'] + [\"{}_{}\".format(name,i) for i in range(NUM_OBJS) for name in col_of_one]\n",
    "df7.columns = new_names\n",
    "\n",
    "# format all id entries because they server important use later\n",
    "print(f\"Please check the following value count of id in each {col_of_one[0]} column\")\n",
    "print(f\"All id values should either be a non-negative whole number (in int or float) or a place holder {PLACE_HOLDER}\")\n",
    "for i in range(NUM_OBJS):\n",
    "    df7[\"{}_{}\".format(col_of_one[0], i)] = df7[\"{}_{}\".format(col_of_one[0], i)].apply(lambda x: int(x.strip()) if type(x)==str else x)\n",
    "    print( df7[\"{}_{}\".format(col_of_one[0], i)].value_counts())\n",
    "    \n",
    "# append empty colunms to match designated number of lines reserved: 14\n",
    "for i in range(BEGIN_IDX, END_IDX):\n",
    "    for name in col_of_one:\n",
    "        df7[name+'_'+str(i)] = PLACE_HOLDER\n",
    "               \n",
    "NUM_OBJS = END_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e376923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MOST important task: Standardization.\n",
    "\n",
    "Details explained in the file doc\n",
    "  \n",
    "!!! May take quite a long time\n",
    "\"\"\"\n",
    "print(\"Sorting started. This may take several seconds up to several minutes, please be patient.\")\n",
    "\n",
    "row_nums = df7.shape[0]    # 4760 this time\n",
    "jump = len(col_of_one)   # 2\n",
    "\n",
    "for row in range(row_nums):\n",
    "    old_row = df7.iloc[row][1:]\n",
    "    new_row = [ [PLACE_HOLDER]*jump ]*NUM_OBJS\n",
    "\n",
    "    \n",
    "    # NOTICE: We only have 4 distinct playerId 1-4, but the raw data have 5 chunks\n",
    "    # Checking raw data, we find there are duplicate chunks\n",
    "    for idx in range(0, 0 + NUM_OBJS*jump, jump):   # 0, 14, 28, ...\n",
    "        objId = old_row[idx]\n",
    "        if objId == PLACE_HOLDER:\n",
    "            # Special case where id is placeholder -99.99 (also those trailing data)\n",
    "            continue\n",
    "        else:\n",
    "            objId = int(objId)\n",
    "            # ego car id=1 should go to objectId_0, id=5 should go to objectId=4 likewise.\n",
    "            new_row[objId] = old_row[idx:idx+jump]\n",
    "            \n",
    "    # flat the list\n",
    "    new_row = [item for sublist in new_row for item in sublist]\n",
    "    df7.iloc[row, 1:] = new_row\n",
    "\n",
    "# do the check after the sort, there should be no output if it's correct\n",
    "for i in range(END_IDX):\n",
    "    row_count = dict(df7[\"{}_{}\".format(col_of_one[0], i)].value_counts())\n",
    "    for key in row_count:\n",
    "        assert key==PLACE_HOLDER or key==i, f\"column {col_of_one[0]}.{i} \\\n",
    "                has wrong id value other than {PLACE_HOLDER} and {i}\"\n",
    "    assert len(row_count) <= 2\n",
    "    \n",
    "    \n",
    "print(\"Work complete. Proceed to csv of pkg9.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d6af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b45b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa94002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18486531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following chunks of code process pkg9 data\n",
    "\"\"\"\n",
    "\n",
    "# Define constants\n",
    "\n",
    "# Get ___pkg9.csv full path\n",
    "file_found = False\n",
    "for f in os.listdir(DATA_DIR):\n",
    "    if len(f) >= 8 and f[-8:]==\"pkg9.csv\":\n",
    "        FILE_PATH = os.path.join(DATA_DIR, f)\n",
    "        file_found = True\n",
    "        break\n",
    "try:\n",
    "    assert file_found==True, \"There is no file ending with pkg9.csv in the folder you choose\"\n",
    "except AssertionError as e:\n",
    "    print(\"The app will exit. Please reopen the app and choose the correct folder.\")\n",
    "    time.sleep(3)\n",
    "    sys.exit()\n",
    "\n",
    "\"\"\"\n",
    "# We want objectId, X, Y, yaw_angle(h after X), Vx, Vy, Ax, Ay as well as dimXYZ, offXYZ for all cars\n",
    "# col index see below (*range(7,13) is 7~12, dimXYZ and offXYZ)\n",
    "\"\"\"\n",
    "index_to_keep = [2, 4, *range(7,13), 13, 14, 16, 22, 23, 31, 32] # remainder of index//PATTERN\n",
    "PATTERN = 39  # number of entries of one road line, which form a pattern\n",
    "col_of_one = [\"objectId\", 'obj_type','dimX','dimY','dimZ','offX','offY','offZ', \\\n",
    "              \"X\", \"Y\", \"yaw_angle\", \"Vx\",\"Vy\", \"Ax\", \"Ay\"]\n",
    "\n",
    "print(f\"Found the csv file {f} in your folder. The process will start now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bdc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" read in the csv and preview.\"\"\"\n",
    "with open(FILE_PATH, 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    MAX_LEN = max(len(_) for _ in reader)\n",
    "\n",
    "    \n",
    "original_col_names = [\"temp.{}\".format(i) for i in range(MAX_LEN)]\n",
    "df9 = pd.read_csv(FILE_PATH, names=original_col_names, low_memory=False)        \n",
    "\n",
    "df9.drop(index=0, axis=0, inplace=True)\n",
    "df9.index -= 1\n",
    "df9.columns = [name.strip() for name in df9.columns]\n",
    "      \n",
    "print(\"Preview the raw csv. The correct column names are not read in because they may not be complete (long enough). Will be fixed later\")\n",
    "print(df9.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a47440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an empty col at the end\n",
      "Please check the following value count of id in each playerId column\n",
      "All id values should either be a non-negative whole number (in int or float) or a place holder -99.99\n",
      "2    3800\n",
      "Name: playerId_0, dtype: int64\n",
      "1    3800\n",
      "Name: playerId_1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Start pre-processing \"\"\"\n",
    "# only keep till the last hundreds of rows\n",
    "# They are safe to and should be deleted because 100 rows <=> 1s in the simulation, and ending row is often incomplete\n",
    "rows = df9.shape[0]\n",
    "num_del = rows%100\n",
    "df9.drop(labels=range(rows-num_del, rows), axis=0, inplace=True)\n",
    "\n",
    "# Automatically define other const dependent on the dataframe\n",
    "while (len(df9.columns)-2)%PATTERN != 0:\n",
    "    # del that col\n",
    "    print(\"Found an empty col at the end\")\n",
    "    df9.drop(df9.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "NUM_OBJS = (len(df9.columns)-2)//PATTERN\n",
    "BEGIN_IDX = NUM_OBJS \n",
    "TARGET = 10 # we want 14\n",
    "END_IDX = 10\n",
    "\n",
    "# delete unused columns\n",
    "cols_to_del = [name for i, name in enumerate(df9.columns) if (i%PATTERN not in index_to_keep and i!=1)]\n",
    "df9 = df9.drop(columns=cols_to_del)\n",
    "\n",
    "\n",
    "# Some other process\n",
    "df9.fillna(PLACE_HOLDER, inplace=True)\n",
    "df9.rename(columns={\"temp.1\":\"simFrame\"}, inplace=True)\n",
    "df9[\"simFrame\"] = df9[\"simFrame\"].astype(np.int64)\n",
    "df9.set_index(\"simFrame\", inplace=True)\n",
    "df9 = df9[~df9.index.duplicated(keep='first')]\n",
    "\n",
    "# replace temp column names with column names we want\n",
    "new_names = [\"{}_{}\".format(name,i) for i in range(NUM_OBJS) for name in col_of_one]\n",
    "df9.columns = new_names\n",
    "\n",
    "# format all id entries because they server important use later\n",
    "print(f\"Please check the following value count of id in each {col_of_one[0]} column\")\n",
    "print(f\"All id values should either be a non-negative whole number (in int or float) or a place holder {PLACE_HOLDER}\")\n",
    "for i in range(NUM_OBJS):\n",
    "    df9[\"{}_{}\".format(col_of_one[0], i)] = df9[\"{}_{}\".format(col_of_one[0], i)].apply(lambda x: int(x.strip()) \\\n",
    "                                                                                        if type(x)==str else x)\n",
    "    print( df9[\"{}_{}\".format(col_of_one[0], i)].value_counts())\n",
    "    \n",
    "# append empty colunms to match designated number of lines reserved: 14\n",
    "for i in range(BEGIN_IDX, END_IDX):\n",
    "    for name in col_of_one:\n",
    "        df9[name+'_'+str(i)] = PLACE_HOLDER\n",
    "               \n",
    "NUM_OBJS = END_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57666c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting started. This may take several seconds up to several minutes, please be patient.\n",
      "Sorting complete. Proceed to next step.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MOST important task: Standardization.\n",
    "\n",
    "Details explained in the file doc\n",
    "  \n",
    "!!! May take quite a long time\n",
    "\"\"\"\n",
    "print(\"Sorting started. This may take several seconds up to several minutes, please be patient.\")\n",
    "\n",
    "row_nums = df9.shape[0]    # 4760 this time\n",
    "jump = len(col_of_one)   # 2\n",
    "\n",
    "for row in range(row_nums):\n",
    "    old_row = df9.iloc[row]\n",
    "    new_row = [ [PLACE_HOLDER]*jump ]*NUM_OBJS\n",
    "\n",
    "    \n",
    "    # NOTICE: We only have 4 distinct playerId 1-4, but the raw data have 5 chunks\n",
    "    # Checking raw data, we find there are duplicate chunks\n",
    "    for idx in range(0, 0 + NUM_OBJS*jump, jump):   # 0, 14, 28, ...\n",
    "        objId = old_row[idx]\n",
    "        if objId == PLACE_HOLDER:\n",
    "            # Special case where id is placeholder -99.99 (also those trailing data)\n",
    "            continue\n",
    "        else:\n",
    "            objId = int(objId)\n",
    "            # ego car id=1 should go to objectId_0, id=5 should go to objectId=4 likewise.\n",
    "            new_row[objId] = old_row[idx:idx+jump]\n",
    "            \n",
    "    # flat the list\n",
    "    new_row = [item for sublist in new_row for item in sublist]\n",
    "    df9.iloc[row] = new_row\n",
    "\n",
    "# do the check after the sort, there should be no output if it's correct\n",
    "for i in range(END_IDX):\n",
    "    row_count = dict(df9[\"{}_{}\".format(col_of_one[0], i)].value_counts())\n",
    "    for key in row_count:\n",
    "        assert key==PLACE_HOLDER or key==i, f\"column {col_of_one[0]}.{i} \\\n",
    "                has wrong id value other than {PLACE_HOLDER} and {i}\"\n",
    "    assert len(row_count) <= 2\n",
    "    \n",
    "    \n",
    "print(\"Work complete. Proceed to csv of pkg10.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fe103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f2fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198febc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following chunks of code process pkg10 data\n",
    "\"\"\"\n",
    "\n",
    "# Define constants\n",
    "\n",
    "# Get ___pkg10.csv full path\n",
    "file_found = False\n",
    "for f in os.listdir(DATA_DIR):\n",
    "    if len(f) >= 9 and f[-9:]==\"pkg10.csv\":\n",
    "        FILE_PATH = os.path.join(DATA_DIR, f)\n",
    "        file_found = True\n",
    "        break\n",
    "try:\n",
    "    assert file_found==True, \"There is no file ending with pkg10.csv in the folder you choose\"\n",
    "except AssertionError as e:\n",
    "    print(\"The app will exit. Please reopen the app and choose the correct folder.\")\n",
    "    time.sleep(3)\n",
    "    sys.exit()\n",
    "\n",
    "# We want playerId, lightMask, steering\n",
    "# which are in col index 2,4\n",
    "index_to_keep = [2,3,0]\n",
    "PATTERN = 4  # number of entries of one obj, which form a pattern\n",
    "col_of_one = [\"playerId\", \"lightMask\", \"steering\"]\n",
    "\n",
    "print(f\"Found the csv file {f} in your folder. The process will start now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f96de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" read in the csv and preview.\"\"\"\n",
    "with open(FILE_PATH, 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    MAX_LEN = max(len(_) for _ in reader)\n",
    "\n",
    "    \n",
    "original_col_names = [\"temp.{}\".format(i) for i in range(MAX_LEN)]\n",
    "df10 = pd.read_csv(FILE_PATH, names=original_col_names, low_memory=False)        \n",
    "\n",
    "df10.drop(index=0, axis=0, inplace=True)\n",
    "df10.index -= 1\n",
    "df10.columns = [name.strip() for name in df10.columns]\n",
    "      \n",
    "print(\"Preview the raw csv. The correct column names are not read in because they may not be complete (long enough). Will be fixed later\")\n",
    "print(df10.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecb5b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an empty col at the end\n",
      "Please check the following value count of id in each playerId column\n",
      "All id values should either be a non-negative whole number (in int or float) or a place holder -99.99\n",
      "2    3800\n",
      "Name: playerId_0, dtype: int64\n",
      "1    3800\n",
      "Name: playerId_1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Start pre-processing \"\"\"\n",
    "# only keep till the last hundreds of rows\n",
    "# They are safe to and should be deleted because 100 rows <=> 1s in the simulation, and ending row is often incomplete\n",
    "rows = df10.shape[0]\n",
    "num_del = rows%100\n",
    "df10.drop(labels=range(rows-num_del, rows), axis=0, inplace=True)\n",
    "\n",
    "# Automatically define other const dependent on the dataframe\n",
    "while (len(df10.columns)-2)%PATTERN != 0:\n",
    "    # del that col\n",
    "    print(\"Found an empty col at the end\")\n",
    "    df10.drop(df10.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "NUM_OBJS = (len(df10.columns)-2)//PATTERN\n",
    "BEGIN_IDX = NUM_OBJS \n",
    "TARGET = 10 # we want 14\n",
    "END_IDX = 10\n",
    "\n",
    "# delete unused columns\n",
    "cols_to_del = [name for i, name in enumerate(df10.columns) if (i%PATTERN not in index_to_keep and i!=1)]\n",
    "df10 = df10.drop(columns=cols_to_del)\n",
    "\n",
    "\n",
    "# Some other process\n",
    "df10.fillna(PLACE_HOLDER, inplace=True)\n",
    "df10.rename(columns={\"temp.1\":\"simFrame\"}, inplace=True)\n",
    "df10[\"simFrame\"] = df10[\"simFrame\"].astype(np.int64)\n",
    "df10.set_index(\"simFrame\", inplace=True)\n",
    "df10 = df10[~df10.index.duplicated(keep='first')]\n",
    "\n",
    "# replace temp column names with column names we want\n",
    "new_names = [\"{}_{}\".format(name,i) for i in range(NUM_OBJS) for name in col_of_one]\n",
    "df10.columns = new_names\n",
    "\n",
    "# format all id entries because they server important use later\n",
    "print(f\"Please check the following value count of id in each {col_of_one[0]} column\")\n",
    "print(f\"All id values should either be a non-negative whole number (in int or float) or a place holder {PLACE_HOLDER}\")\n",
    "for i in range(NUM_OBJS):\n",
    "    df10[\"{}_{}\".format(col_of_one[0], i)] = df10[\"{}_{}\".format(col_of_one[0], i)].apply(lambda x: int(x.strip()) \\\n",
    "                                                                                        if type(x)==str else x)\n",
    "    print( df10[\"{}_{}\".format(col_of_one[0], i)].value_counts())\n",
    "    \n",
    "# append empty colunms to match designated number of lines reserved: 14\n",
    "for i in range(BEGIN_IDX, END_IDX):\n",
    "    for name in col_of_one:\n",
    "        df10[name+'_'+str(i)] = PLACE_HOLDER\n",
    "               \n",
    "NUM_OBJS = END_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e3a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting started. This may take several seconds up to several minutes, please be patient.\n",
      "Sorting complete. Proceed to next step.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MOST important task: Standardization.\n",
    "\n",
    "Details explained in the file doc\n",
    "  \n",
    "!!! May take quite a long time\n",
    "\"\"\"\n",
    "print(\"Sorting started. This may take several seconds up to several minutes, please be patient.\")\n",
    "\n",
    "row_nums = df10.shape[0]    # 4760 this time\n",
    "jump = len(col_of_one)   # 2\n",
    "\n",
    "for row in range(row_nums):\n",
    "    old_row = df10.iloc[row]\n",
    "    new_row = [ [PLACE_HOLDER]*jump ]*NUM_OBJS\n",
    "\n",
    "    \n",
    "    # NOTICE: We only have 4 distinct playerId 1-4, but the raw data have 5 chunks\n",
    "    # Checking raw data, we find there are duplicate chunks\n",
    "    for idx in range(0, 0 + NUM_OBJS*jump, jump):   # 0, 14, 28, ...\n",
    "        objId = old_row[idx]\n",
    "        if objId == PLACE_HOLDER:\n",
    "            # Special case where id is placeholder -99.99 (also those trailing data)\n",
    "            continue\n",
    "        else:\n",
    "            objId = int(objId)\n",
    "            # ego car id=1 should go to objectId_0, id=5 should go to objectId=4 likewise.\n",
    "            new_row[objId] = old_row[idx:idx+jump]\n",
    "            \n",
    "    # flat the list\n",
    "    new_row = [item for sublist in new_row for item in sublist]\n",
    "    df10.iloc[row] = new_row\n",
    "\n",
    "# do the check after the sort, there should be no output if it's correct\n",
    "for i in range(END_IDX):\n",
    "    row_count = dict(df10[\"{}_{}\".format(col_of_one[0], i)].value_counts())\n",
    "    for key in row_count:\n",
    "        assert key==PLACE_HOLDER or key==i, f\"column {col_of_one[0]}.{i} \\\n",
    "                has wrong id value other than {PLACE_HOLDER} and {i}\"\n",
    "    assert len(row_count) <= 2\n",
    "    \n",
    "    \n",
    "print(\"Work complete. Proceed to csv of pkg10.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178edf77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6151c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe467c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following chunks of code process pkg20 data\n",
    "\"\"\"\n",
    "\n",
    "# Define constants\n",
    "\n",
    "# Get ___pkg20.csv full path\n",
    "file_found = False\n",
    "for f in os.listdir(DATA_DIR):\n",
    "    if len(f) >= 9 and f[-9:]==\"pkg20.csv\":\n",
    "        FILE_PATH = os.path.join(DATA_DIR, f)\n",
    "        file_found = True\n",
    "        break\n",
    "try:\n",
    "    assert file_found==True, \"There is no file ending with pkg20.csv in the folder you choose\"\n",
    "except AssertionError as e:\n",
    "    print(\"The app will exit. Please reopen the app and choose the correct folder.\")\n",
    "    time.sleep(3)\n",
    "    sys.exit()\n",
    "\n",
    "# We want playerId, lightMask, steering\n",
    "# which are in col index 2,4\n",
    "index_to_keep = [2,3,0]\n",
    "PATTERN = 4  # number of entries of one obj, which form a pattern\n",
    "col_of_one = [\"playerId\", \"lightMask\", \"steering\"]\n",
    "\n",
    "print(f\"Found the csv file {f} in your folder. The process will start now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" read in the csv and preview.\"\"\"\n",
    "with open(FILE_PATH, 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    MAX_LEN = max(len(_) for _ in reader)\n",
    "\n",
    "    \n",
    "original_col_names = [\"temp.{}\".format(i) for i in range(MAX_LEN)]\n",
    "df10 = pd.read_csv(FILE_PATH, names=original_col_names, low_memory=False)        \n",
    "\n",
    "df10.drop(index=0, axis=0, inplace=True)\n",
    "df10.index -= 1\n",
    "df10.columns = [name.strip() for name in df10.columns]\n",
    "      \n",
    "print(\"Preview the raw csv. The correct column names are not read in because they may not be complete (long enough). Will be fixed later\")\n",
    "print(df10.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919abe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an empty col at the end\n",
      "Please check the following value count of id in each playerId column\n",
      "All id values should either be a non-negative whole number (in int or float) or a place holder -99.99\n",
      "2    3800\n",
      "Name: playerId_0, dtype: int64\n",
      "1    3800\n",
      "Name: playerId_1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Start pre-processing \"\"\"\n",
    "# only keep till the last hundreds of rows\n",
    "# They are safe to and should be deleted because 100 rows <=> 1s in the simulation, and ending row is often incomplete\n",
    "rows = df10.shape[0]\n",
    "num_del = rows%100\n",
    "df10.drop(labels=range(rows-num_del, rows), axis=0, inplace=True)\n",
    "\n",
    "# Automatically define other const dependent on the dataframe\n",
    "while (len(df10.columns)-2)%PATTERN != 0:\n",
    "    # del that col\n",
    "    print(\"Found an empty col at the end\")\n",
    "    df10.drop(df10.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "NUM_OBJS = (len(df10.columns)-2)//PATTERN\n",
    "BEGIN_IDX = NUM_OBJS \n",
    "TARGET = 10 # we want 14\n",
    "END_IDX = 10\n",
    "\n",
    "# delete unused columns\n",
    "cols_to_del = [name for i, name in enumerate(df10.columns) if (i%PATTERN not in index_to_keep and i!=1)]\n",
    "df10 = df10.drop(columns=cols_to_del)\n",
    "\n",
    "\n",
    "# Some other process\n",
    "df10.fillna(PLACE_HOLDER, inplace=True)\n",
    "df10.rename(columns={\"temp.1\":\"simFrame\"}, inplace=True)\n",
    "df10[\"simFrame\"] = df10[\"simFrame\"].astype(np.int64)\n",
    "df10.set_index(\"simFrame\", inplace=True)\n",
    "df10 = df10[~df10.index.duplicated(keep='first')]\n",
    "\n",
    "# replace temp column names with column names we want\n",
    "new_names = [\"{}_{}\".format(name,i) for i in range(NUM_OBJS) for name in col_of_one]\n",
    "df10.columns = new_names\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "We have special processing requirement for pkg20.\n",
    "\n",
    "Only data with playerId == 0 should be kept.\n",
    "So, we can skip sorting, which aligns all objects in each row based on id values.\n",
    "Instead, we simply check each row and pick the section with id value==0, or use place holder otherwise.\n",
    "\n",
    "Further more, original 'playerId', which means which player detect this sign, will be renamed to signId.\n",
    "Traffic sign isn't given an id in VTD design.\n",
    "\"\"\"\n",
    "id_col = []\n",
    "roadDist_col = []\n",
    "value_col = []\n",
    "row_nums = df20.shape[0]    # Should be 4664 this time\n",
    "\n",
    "if not list(df20.columns):\n",
    "    # For pkg 20, there could be no valid data at all (empty df with no cols)\n",
    "    print(\"Got an empty df, a normal case for pkg20\")\n",
    "    id_col = [PLACE_HOLDER]*row_nums\n",
    "    roadDist_col = [PLACE_HOLDER]*row_nums\n",
    "    value_col = [PLACE_HOLDER]*row_nums\n",
    "    \n",
    "    \n",
    "else:\n",
    "    got = False\n",
    "    # Start to loop\n",
    "    for row in range(row_nums):\n",
    "        this_row = df20.iloc[row]\n",
    "        got = False\n",
    "        for i in range(NUM_OBJS):\n",
    "            if this_row[\"signId.{}\".format(i)] == 0:\n",
    "                id_col.append(this_row[\"signId.{}\".format(i)])\n",
    "                roadDist_col.append(this_row[\"roadDist.{}\".format(i)])\n",
    "                value_col.append(this_row[\"value.{}\".format(i)])\n",
    "                got = True\n",
    "                break\n",
    "        if not got:\n",
    "            # Strange thing found: some rows (<100 out of 8000+) have no data of ego car\n",
    "            id_col.append(PLACE_HOLDER)\n",
    "            roadDist_col.append(PLACE_HOLDER)\n",
    "            value_col.append(PLACE_HOLDER)\n",
    "            # print(\"row num: \", row)\n",
    "\n",
    "    # IMPORTANT: since each row must have ego car data, they should match\n",
    "    assert len(roadDist_col) == len(value_col) == row_nums == len(id_col), \\\n",
    "            f\"the length of some row can't match with original length {row_nums}\"\n",
    "    \n",
    "    \n",
    "df20_new = pd.DataFrame({\n",
    "    'simFrame': df20.index,\n",
    "    \"signId\": id_col,\n",
    "    \"roadDist\": roadDist_col,\n",
    "    \"value\": value_col\n",
    "})\n",
    "df20_new.set_index('simFrame', inplace=True)\n",
    "\n",
    "\n",
    "row_count = dict(df20_new[\"signId\"].value_counts())\n",
    "for key in row_count:\n",
    "    assert key==PLACE_HOLDER or key==0, f\"column signId \\\n",
    "            has wrong id value other than {PLACE_HOLDER} and 0\"\n",
    "assert len(row_count) <= 2\n",
    "    \n",
    "print(\"Work complete. Proceed to the join of 5 processed csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
